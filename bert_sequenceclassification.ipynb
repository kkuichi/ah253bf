{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828a69f4ed2d0ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:58:37.331131Z",
     "start_time": "2025-05-19T07:58:33.991694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annahavryliak/IdeaProjects/ZS2/pythonProject/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/annahavryliak/IdeaProjects/ZS2/pythonProject/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#Import knižníc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb5111d73e431af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:58:38.180567Z",
     "start_time": "2025-05-19T07:58:38.136213Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stiahnutie dataset\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "val_data = pd.read_csv('data/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d595e3054eda5e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:58:40.293078Z",
     "start_time": "2025-05-19T07:58:40.285531Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #Previesť text na malé písmená\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Odstránenie adries URL\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    #Odstránenie hashtagov (iba symbol „#“, text ponechajte)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    \n",
    "    #Odstránenie špeciálnych znakov a čísel\n",
    "    text = ''.join(c for c in text if c.isalnum() or c.isspace())\n",
    "    \n",
    "    #Odstránenie zbytočných medzier\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355e40a5d0d88610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:58:42.372494Z",
     "start_time": "2025-05-19T07:58:42.187481Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['cleaned_tweet'] = train_data['tweet'].apply(clean_text)\n",
    "val_data['cleaned_tweet'] = val_data['tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552a04db716cd76f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:58:44.320549Z",
     "start_time": "2025-05-19T07:58:44.085494Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annahavryliak/IdeaProjects/ZS2/pythonProject/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Stiahnutie tokenizéra\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c925bd425c15de1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:58:45.695323Z",
     "start_time": "2025-05-19T07:58:45.691477Z"
    }
   },
   "outputs": [],
   "source": [
    "#Tokenizácia textu s obmedzením dĺžky\n",
    "def tokenize_text(text, tokenizer, max_length=128):\n",
    "    tokens = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return tokens['input_ids'], tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac8bfebadeb86e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:58:53.735761Z",
     "start_time": "2025-05-19T07:58:47.957223Z"
    }
   },
   "outputs": [],
   "source": [
    "#Vytvorenie nových stĺpcov pre tokeny\n",
    "train_data['input_ids'] = train_data['cleaned_tweet'].apply(lambda x: tokenize_text(x, tokenizer)[0])\n",
    "train_data['attention_mask'] = train_data['cleaned_tweet'].apply(lambda x: tokenize_text(x, tokenizer)[1])\n",
    "\n",
    "val_data['input_ids'] = val_data['cleaned_tweet'].apply(lambda x: tokenize_text(x, tokenizer)[0])\n",
    "val_data['attention_mask'] = val_data['cleaned_tweet'].apply(lambda x: tokenize_text(x, tokenizer)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "611f2cc903190b48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:58:54.619963Z",
     "start_time": "2025-05-19T07:58:54.601817Z"
    }
   },
   "outputs": [],
   "source": [
    "#Previesť label ('real' -> 0, 'fake' -> 1)\n",
    "train_data['label'] = train_data['label'].map({'real': 0, 'fake': 1})\n",
    "val_data['label'] = val_data['label'].map({'real': 0, 'fake': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2102af9daaf44e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:58:55.773268Z",
     "start_time": "2025-05-19T07:58:55.723220Z"
    }
   },
   "outputs": [],
   "source": [
    "#Vytvorenie triedy pre dátasety\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.input_ids = torch.cat(data['input_ids'].values.tolist(), dim=0)\n",
    "        self.attention_masks = torch.cat(data['attention_mask'].values.tolist(), dim=0)\n",
    "        self.labels = torch.tensor(data['label'].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_masks[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "#Vytvorenie dátasetov\n",
    "train_dataset = NewsDataset(train_data)\n",
    "val_dataset = NewsDataset(val_data)\n",
    "\n",
    "#Vytvorenie DataLoader\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fb3abc4c8a95aaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:59:00.416162Z",
     "start_time": "2025-05-19T07:58:57.414873Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annahavryliak/IdeaProjects/ZS2/pythonProject/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definícia zariadenia\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Stiahnutie modelu BERT\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28022c318e2e1592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:59:03.999637Z",
     "start_time": "2025-05-19T07:59:02.871074Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annahavryliak/IdeaProjects/ZS2/pythonProject/.venv/lib/python3.12/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Stiahnutie optimalizátor\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "#Definovanie epoch\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38caf78f87d939f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:59:06.220393Z",
     "start_time": "2025-05-19T07:59:06.212296Z"
    }
   },
   "outputs": [],
   "source": [
    "#Kontrola preds a labelov\n",
    "def compute_accuracy(preds, labels):\n",
    "    if isinstance(preds, torch.Tensor):\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "\n",
    "    return accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3760cdbf59fd98cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:59:13.514920Z",
     "start_time": "2025-05-19T07:59:13.504026Z"
    }
   },
   "outputs": [],
   "source": [
    "#Funkcia pre skolenie modelu\n",
    "def train_model(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1).detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "\n",
    "        total_accuracy += compute_accuracy(preds, labels)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_accuracy = total_accuracy / len(train_loader)\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a67e2d8450230129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:59:15.463166Z",
     "start_time": "2025-05-19T07:59:15.444551Z"
    }
   },
   "outputs": [],
   "source": [
    "#Funkcia doučovanie modelu\n",
    "def validate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1).detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            total_accuracy += compute_accuracy(preds, labels)\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    avg_accuracy = total_accuracy / len(val_loader)\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb276f51d223b2ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T07:59:17.823902Z",
     "start_time": "2025-05-19T07:59:17.770938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([16, 128])\n",
      "Attention mask shape: torch.Size([16, 128])\n",
      "Labels shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "#Kontrola jedného batchu\n",
    "for batch in train_loader:\n",
    "    print(\"Input IDs shape:\", batch['input_ids'].shape)\n",
    "    print(\"Attention mask shape:\", batch['attention_mask'].shape)\n",
    "    print(\"Labels shape:\", batch['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20081e709975ab2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T15:04:33.098590Z",
     "start_time": "2025-05-19T07:59:20.411459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.2854, Train Accuracy: 0.8845\n",
      "Val Loss: 0.1620, Val Accuracy: 0.9389\n",
      "Epoch 2/10\n",
      "Train Loss: 0.1114, Train Accuracy: 0.9605\n",
      "Val Loss: 0.1336, Val Accuracy: 0.9436\n",
      "Epoch 3/10\n",
      "Train Loss: 0.0537, Train Accuracy: 0.9829\n",
      "Val Loss: 0.1736, Val Accuracy: 0.9492\n",
      "Epoch 4/10\n",
      "Train Loss: 0.0324, Train Accuracy: 0.9890\n",
      "Val Loss: 0.1553, Val Accuracy: 0.9506\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0165, Train Accuracy: 0.9950\n",
      "Val Loss: 0.1756, Val Accuracy: 0.9548\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0092, Train Accuracy: 0.9975\n",
      "Val Loss: 0.2267, Val Accuracy: 0.9454\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0118, Train Accuracy: 0.9964\n",
      "Val Loss: 0.2396, Val Accuracy: 0.9411\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0123, Train Accuracy: 0.9961\n",
      "Val Loss: 0.1825, Val Accuracy: 0.9538\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0049, Train Accuracy: 0.9988\n",
      "Val Loss: 0.2276, Val Accuracy: 0.9566\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0076, Train Accuracy: 0.9975\n",
      "Val Loss: 0.1946, Val Accuracy: 0.9562\n"
     ]
    }
   ],
   "source": [
    "#Školenie a validacia modelu\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    #Školenie\n",
    "    train_loss, train_acc = train_model(model, train_loader, optimizer, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    #Validacia\n",
    "    val_loss, val_acc = validate_model(model, val_loader, device)\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75b640f923e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uloženie modelu\n",
    "save_directory = \"bert_seq\"\n",
    "\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "torch.save(optimizer.state_dict(), os.path.join(save_directory, 'optimizer.pt'))\n",
    "\n",
    "config = model.config\n",
    "config.save_pretrained(save_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
